{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzm06HuarQCB"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langgraph google-api-python-client langchain[google-genai]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def _set_env(key):\n",
        "    value = os.environ.get(key)\n",
        "    if value is None:\n",
        "        value = input(f\"Please enter your {key}: \")\n",
        "        os.environ[key] = value\n",
        "\n",
        "# Set keys\n",
        "_set_env(\"GOOGLE_API_KEY\")   # From Google Cloud Console\n",
        "_set_env(\"GOOGLE_CSE_ID\")    # From Programmable Search Engine (CSE)\n"
      ],
      "metadata": {
        "id": "o1KtjUqxrzow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query: str, max_results: int = 3):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=os.environ[\"GOOGLE_API_KEY\"])\n",
        "    res = service.cse().list(q=query, cx=os.environ[\"GOOGLE_CSE_ID\"], num=max_results).execute()\n",
        "    results = res.get(\"items\", [])\n",
        "    return \"\\n\".join([f\"{item['title']}: {item['link']}\" for item in results])\n",
        "\n",
        "# Wrap as a LangChain tool\n",
        "google_tool = Tool(\n",
        "    name=\"GoogleSearch\",\n",
        "    func=google_search,\n",
        "    description=\"Use this tool to search the web using Google Search\"\n",
        ")\n",
        "\n",
        "tools = [google_tool]\n"
      ],
      "metadata": {
        "id": "MFg75GsgwcKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# If not already set\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Initialize Gemini model\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n",
        "llm_with_tools = llm.bind_tools(tools)\n"
      ],
      "metadata": {
        "id": "pFUPoPYwwl3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n"
      ],
      "metadata": {
        "id": "J9jeaqkMwr5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "class BasicToolNode:\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "tool_node = BasicToolNode(tools=[google_tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n"
      ],
      "metadata": {
        "id": "qWlbx0o0wxM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_tools(state: State):\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "graph_builder.add_conditional_edges(\"chatbot\", route_tools, {\"tools\": \"tools\", END: END})\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()\n"
      ],
      "metadata": {
        "id": "5xo3Tx39w2qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        user_input = \"What is LangGraph?\"\n",
        "        print(\"User:\", user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break\n"
      ],
      "metadata": {
        "id": "JsXROQ7bw7Bn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}